{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"/raid/cs18resch11003/aditi/transfer-learning-conv-ai/ParlAI/data/ConvAI2/test_self_original_no_cands.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open(datapath, 'r')\n",
    "lines = data.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "personality = []\n",
    "persona = []\n",
    "for idx, line in enumerate(lines):\n",
    "    if \"your persona:\" in line:\n",
    "        line = line.strip()\n",
    "        line = line.replace(\"your persona:\",\"\")\n",
    "        line = line[3:]\n",
    "        persona.append(line)\n",
    "    else:\n",
    "        if len(persona)!=0:\n",
    "            personality.append(persona)\n",
    "            persona = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations = []\n",
    "conversation = []\n",
    "for idx, line in enumerate(lines):\n",
    "    if \"your persona:\" not in line:\n",
    "        line = line.strip()\n",
    "        line = line[2:]\n",
    "        conversation.append(line)\n",
    "    else:\n",
    "        if len(conversation)!=0:\n",
    "            conversations.append(conversation)\n",
    "            conversation = []\n",
    "conversations.append(conversation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = []\n",
    "replies = []\n",
    "\n",
    "for conversation in conversations:\n",
    "    temp_prompt = []\n",
    "    temp_replies = []\n",
    "    for turn in conversation:\n",
    "        utterance1, utterance2 = turn.split(\"\\t\")\n",
    "        utterance1 = utterance1.strip()\n",
    "        utterance2 = utterance2.strip()\n",
    "\n",
    "        temp_prompt.append(utterance1)\n",
    "        temp_replies.append(utterance2)\n",
    "    prompts.append(temp_prompt)\n",
    "    replies.append(temp_replies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(personality)==(len(prompts)+len(replies))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i love to meet new people.',\n",
       " 'i have a turtle named timothy.',\n",
       " 'my favorite sport is ultimate frisbee.',\n",
       " 'my parents are living in bora bora.',\n",
       " 'autumn is my favorite season.']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personality[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello , how are you doing tonight ?',\n",
       " 'i am great . i just got back from the club .',\n",
       " 'i would rather eat chocolate cake during this season .',\n",
       " 'i went to club chino . what show are you watching ?',\n",
       " 'do you live in a house or apartment ?',\n",
       " 'i love those shows . i am really craving cake .',\n",
       " 'it matters because i have a sweet tooth .',\n",
       " 'my family lives in alaska . it is freezing down there .']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i am well an loving this interaction how are you ?',\n",
       " 'this is my favorite time of the year season wise',\n",
       " 'what club did you go to ? me an timothy watched tv',\n",
       " 'lol oh okay kind of random',\n",
       " 'we watched a show about animals like him',\n",
       " 'why does that matter any ? i went outdoors to play frisbee',\n",
       " 'so ? lol i want to meet my family at home in bora',\n",
       " 'i bet it is oh i could not']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replies[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-21 17:51:41.893946: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-21 17:51:41.893999: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/raid/cs18resch11003/anaconda3/envs/dialogpt/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2022-07-21 17:51:45.000570: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-21 17:51:45.000676: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-07-21 17:51:45.000778: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-07-21 17:51:45.003019: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-07-21 17:51:45.003079: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-07-21 17:51:45.003131: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-07-21 17:51:45.003141: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-07-21 17:51:45.003548: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFGPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# add the EOS token as PAD token to avoid warnings\n",
    "model = TFGPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\")\n",
    "\n",
    "encoder_input_str = \"translate English to German: How old are you?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[13959,  1566,    12,  2968,    10,   571,   625,    33,    25,    58,\n",
      "             1]])\n",
      "Wie alt bist du?\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(encoder_input_str, return_tensors=\"pt\").input_ids\n",
    "\n",
    "print(input_ids)\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    num_beams=10,\n",
    "    num_return_sequences=1,\n",
    "    no_repeat_ngram_size=1,\n",
    "    remove_invalid_values=True,\n",
    ")\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2758966/1965156877.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('dialogpt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "47a16a6705441b6dda92a294eb31436c27952dbca87d6ec649ac2e31022a0dfe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
